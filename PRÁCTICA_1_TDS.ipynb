{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRÁCTICA 1\n",
    "# ESTIMACIÓN DE LA AUTOCORRELACIÓN\n",
    "\n",
    "En muchas aplicaciones es necesario obtener la autocorrelación de un proceso aleatorio a partir de un\n",
    "número finito de muestras de señal $x(n)$ ($n = 0,1, \\dots, N-1$). Un estimador muy común es el siguiente:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_x(k) = \\frac{1}{N} \\sum_{n=|k|}^{N-1} x(n) x^*(n - |k|) \n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "donde se está suponiendo implícitamente que $x(n) = 0$ fuera del intervalo considerado. Esto es equivalente\n",
    "a considerar que se ha aplicado una ventana $w(n)$ rectangular a la señal $x_{\\text{org}}(n)$ que originalmente se\n",
    "extendía desde $n = -\\infty$ hasta $n = \\infty$, de modo que $x(n) = x_{\\text{org}}(n) w(n)$.\n",
    "\n",
    "Alternativamente, la expresión (1) puede entenderse como una convolución:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat{r}_x(k) = \\frac{1}{N} x(k) * x^*(-k) \\tag{2}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\n",
    "### NOTA para implementación en Python:\n",
    "Todas las comparaciones se efectuarán haciendo uso de las utilidades gráficas de `matplotlib.pyplot`.\n",
    "\n",
    "### Módulos para la implementación en Python:\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "```\n",
    "\n",
    "___\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 1\n",
    "**(Cuestión teórica)**  \n",
    "Determinar si la estimación (1) propuesta para la autocorrelación tiene o no sesgo.\n",
    "\n",
    "La estimación dada por  \n",
    "$$\\hat{r}_x(k) = \\frac{1}{N} \\sum_{n=|k|}^{N-1} x(n) x^*(n - |k|)$$  \n",
    "se considera un **estimador sesgado** de la autocorrelación, ya que el factor de normalización es $\\frac{1}{N}$ en lugar de $\\frac{1}{N - |k|}$. Para que fuera no sesgado, debería compensarse la reducción en el número de términos efectivos cuando $|k|$ crece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (No hay código en este ejercicio, es una cuestión teórica)\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 2\n",
    "Generar $N = 1000$ muestras de un ruido blanco Gaussiano de media nula y varianza unidad mediante\n",
    "el comando `np.random.randn(N)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# EJERCICIO 2\n",
    "\n",
    "N = 1000  \n",
    "mu = 3.0\n",
    "sigma = 1.0\n",
    "                \n",
    "x1 = np.random.normal(mu, sigma, N)     # Ruido blanco Gaussiano de media mu y varianza sigma^2         \n",
    "x2 = np.random.randn(N)                 # Ruido blanco Gaussiano de media 0 y varianza 1\n",
    "x3 = mu + sigma * np.random.randn(N)    # Ruido blanco Gaussiano de media mu y varianza sigma^2\n",
    "x4 = np.random.uniform(-1, 1, N)        # Ruido blanco uniforme entre -1 y 1\n",
    "\n",
    "seleccion = x1          # Seleccionar aquí la variable que se quiere analizar\n",
    "print(\"Primeras 10 muestras del ruido generado:\")\n",
    "print(seleccion[:10])   # o seleccion[0:10] para Python 2\n",
    "print(\"\\nMedia aproximada:\", np.mean(seleccion))\n",
    "print(\"Varianza aproximada:\", np.var(seleccion))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 3\n",
    "Estimar la autocorrelación $r_x(k)$ ( $k = -(N - 1), \\dots, N - 1$ ) de acuerdo con la expresión (1), y también haciendo uso de los comandos `convolve` (ecuación (2)) y `correlate` de numpy. Explicar los resultados obtenidos comparando gráficamente con la función de autocorrelación verdadera $r_x(k) = \\delta(k)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# EJERCICIO 3\n",
    "\n",
    "def autocorr_biased(x):\n",
    "    N = len(x)\n",
    "    r = np.zeros(2*N - 1, dtype=complex)  # k desde -(N-1) hasta (N-1)\n",
    "    for k in range(-(N-1), N):\n",
    "        idx = k + (N-1)\n",
    "        suma = 0\n",
    "        for n in range(abs(k), N):\n",
    "            suma += x[n] * np.conjugate(x[n - abs(k)])\n",
    "        r[idx] = suma / N\n",
    "    return r\n",
    "\n",
    "# Seleccionamos x3 como la variable x\n",
    "x = x1 # Seleccionar aquí la variable que se quiere analizar. Mire el ejercicio 2 para más detalles.\n",
    "\n",
    "# Estimación manual (sesgada)\n",
    "r_manual = autocorr_biased(x)\n",
    "\n",
    "# Usando convolve (ecuación (2))\n",
    "# r_x(k) = (1/N) * x(k) * x^*(-k) Equivale a convolucionar x(n) con x^*(-n) y dividir por N\n",
    "r_conv = np.convolve(x, np.conjugate(x[::-1]), mode='full') / N\n",
    "\n",
    "# Usando correlate de numpy (sesgado)\n",
    "r_corr = np.correlate(x, x, mode='full') / N # Se divide por N para que sea no sesgada\n",
    "\n",
    "lags = np.arange(-(N-1), N) # Genera array de enteros desde -(N-1) hasta N-1 (incluyendo -(N-1) y excluyendo N)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lags, r_manual.real, label='Autocorrelación manual (sesgada)')\n",
    "plt.plot(lags, r_conv.real, '--', label='Convolve (sesgada)')\n",
    "plt.plot(lags, r_corr.real, ':', label='Correlate (sesgada)')\n",
    "plt.title('Comparación de autocorrelaciones (sesgadas)')\n",
    "plt.xlabel('Desplazamiento (k)')\n",
    "plt.ylabel('r_x(k)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se obtienen resultados distintos para cada vector $xX$ (donde $X \\in \\{1, 2, 3, 4\\}$ son los vectores del ejercicio anterior) ya que la varianza y la media de este varía.\n",
    "\n",
    "La autocorrelación se puede expresar en términos de una convolución. Se demuestra que:\n",
    "$$ r_x(k) = \\frac{1}{N}\\sum_{k=-\\infty}^{\\infty} x(n)x^*(n-k) =  \\frac{1}{N} x(k)*x^*(-k)$$\n",
    "\n",
    "En la autocorrelación **sesgada** (dividiendo siempre por $N$) y con modo *full*, a medida que aumenta $|k|$, cada retardo suma menos productos (porque hay menos solapamiento entre los índices). Sin embargo, la normalización permanece fija en $N$. Esto provoca que la amplitud de la autocorrelación decrezca linealmente con $|k|$ y se forme esa \"pirámide\" para $xX$ donde la media no sea nula. Cuando esta media es cero, los valores varían entre negativos y positivos con la misma probabilidad y la acumulación de estos tenderá a la media.   \n",
    "\n",
    "Para corregir el sesgo, se define la autocorrelación **no sesgada** como:\n",
    "\n",
    "$$\\tilde{r}_x(k) = \\frac{N}{N - |k|} \\hat{r}_x(k)$$\n",
    "Podemos escribir esta relación como:\n",
    "\n",
    "$$\\hat{r}_x(k) = \\left( 1 - \\frac{|k|}{N} \\right) \\tilde{r}_x(k)$$\n",
    "\n",
    "donde el término de ponderación $W_B(k)$  se define como:\n",
    "\n",
    "$$W_B(k) = 1 - \\frac{|k|}{N}$$\n",
    "\n",
    "Este término actúa como un **factor de corrección**, eliminando el sesgo en la estimación.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 4\n",
    "Obtener ahora la estima **sin sesgo** de la autocorrelación usando el comando `correlate` (MatLab: `xcorr`) de numpy. Comparar gráficamente esta estima con la obtenida mediante el estimador sesgado de los apartados anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# EJERCICIO 4\n",
    "\n",
    "def autocorr_unbiased(x):\n",
    "    N = len(x)\n",
    "    r = np.correlate(x, x, mode='full') / N # Autocorrelación sesgada\n",
    "    lags = np.arange(-(N-1), N)\n",
    "    \n",
    "    # Normalización sin sesgo\n",
    "    unbiased_r = np.zeros_like(r, dtype=float)  # Inicializa array de floats\n",
    "    for i, k in enumerate(lags):\n",
    "        unbiased_r[i] = r[i] * N/(N - abs(k))   # Transforma a no sesgado\n",
    "    return unbiased_r, lags\n",
    "\n",
    "r_unbiased, lags = autocorr_unbiased(x)         # LLama a la función autocorr_unbiased\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lags, r_corr.real, label='Sesgado (Correlate / N)')\n",
    "plt.plot(lags, r_unbiased, '--', label='No sesgado')\n",
    "plt.title('Comparación entre estimador sesgado y no sesgado')\n",
    "plt.xlabel('Desplazamiento (k)')\n",
    "plt.ylabel('r_x(k)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La versión **no sesgada** divide cada valor por ($N - |k|$) en vez de N, por lo que corrige la disminución de muestras efectivas para grandes |$k$|. Cuando $k$ aumenta, la estimación es peor ya que se \"participan\" menos muestras y, por ende, el enfoque sin sesgo atrubuye en estos casos un \"peso\" menor.\n",
    "\n",
    "En caso de haber elegido un $x$ con media no nula, véase como la función está \"elevada\" a $m_{x}\\cdot m_{x}$ ya que se trata de un momento no centrado pues se define como\n",
    "$$ R_x(k) = VAR_x(k) + m_x^2$$\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 5\n",
    "Obtener las estimaciones de la autocorrelación con sesgo y sin sesgo para el mismo ruido anterior\n",
    "pero añadiendo una media unitaria. ¿Cómo debería ser la autocorrelación original en este caso?\n",
    "Explicar los resultados obtenidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# EJERCICIO 5\n",
    "\n",
    "# Generamos el mismo ruido pero con media 1\n",
    "x_mean1 = np.random.randn(N) + 1\n",
    "\n",
    "# Estimador sesgado\n",
    "r_corr_mean1 = np.correlate(x_mean1, x_mean1, mode='full') / N\n",
    "\n",
    "# Estimador no sesgado\n",
    "r_unbiased_mean1, lags = autocorr_unbiased(x_mean1)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(lags, r_corr_mean1.real, label='Sesgado con media 1')\n",
    "plt.plot(lags, r_unbiased_mean1, '--', label='No sesgado con media 1')\n",
    "plt.title('Autocorrelación con y sin sesgo (ruido con media 1)')\n",
    "plt.xlabel('Desplazamiento (k)')\n",
    "plt.ylabel('r_x(k)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado se explica en el anterior ejercicio pero se explicará de nuevo.\n",
    "\n",
    "Teóricamente, con media 1, la autocorrelación de una señal $x(n) = w(n) + 1$ \n",
    "(donde $w(n)$ es ruido blanco de varianza 1) tiene un valor en $k=0$ que \n",
    "incluye la varianza y el cuadrado de la media ($1^2 = 1$). Para $k \\neq 0$, la autocorrelación debe reflejar la correlación de $w(n)$ \n",
    "(que es prácticamente $\\delta(k)$) más la contribución de la media. Ya que\n",
    "\n",
    "```python\n",
    "x = np.random.normal(mu, sigma, N) = mu + sigma * np.random.randn(N) \n",
    "```\n",
    "Observamos un incremento en todos los valores de $r_x(k)$ debido a la media unitaria.\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EJERCICIO 6\n",
    "Aplicar los estimadores de media y varianza muestral sobre 100 estimas de la autocorrelación, cada\n",
    "una de ellas obtenida a partir de una secuencia distinta de ruido blanco de media unidad. ¿Qué\n",
    "sucede si aumentas el número de estimas a 1000, 10000, etc? ¿A qué tiende la media? ¿Qué indica\n",
    "la varianza? Comparar los resultados al usar los estimadores sesgado y no sesgado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# EJERCICIO 6\n",
    "\n",
    "num_estimates_list = [10, 100, 1000, 10000]\n",
    "N = 1000 \n",
    "\n",
    "for num_estimates in num_estimates_list: # Para cada valor de num_estimates\n",
    "    sesgadas = []     # Lista para guardar las estimaciones sesgadas\n",
    "    no_sesgadas = []  # Lista para guardar las estimaciones no sesgadas\n",
    "\n",
    "    for _ in range(num_estimates): # Itera sobre una cantidad de la lista num_estimates\n",
    "        x_sample = np.random.randn(N) + 1 # Genera una muestra de ruido con media 1\n",
    "        \n",
    "        r_sesg = np.correlate(x_sample, x_sample, mode='full') / N\n",
    "        r_nosesg, _ = autocorr_unbiased(x_sample)  # _ descarta el segundo valor de retorno\n",
    "        \n",
    "        sesgadas.append(r_sesg[N-1])      # append añade un elemento al final de la lista\n",
    "        no_sesgadas.append(r_nosesg[N-1])\n",
    "\n",
    "    mean_sesgadas = np.mean(sesgadas)\n",
    "    var_sesgadas = np.var(sesgadas)\n",
    "\n",
    "    mean_nosesgadas = np.mean(no_sesgadas)\n",
    "    var_nosesgadas = np.var(no_sesgadas)\n",
    "\n",
    "    print(f\"num_estimates = {num_estimates}\")\n",
    "    print(f\"Media (sesgado)   = {mean_sesgadas:.4f}, Var (sesgado)   = {var_sesgadas:.4e}\")\n",
    "    print(f\"Media (no sesgado)= {mean_nosesgadas:.4f}, Var (no sesgado)= {var_nosesgadas:.4e}\")\n",
    "    print(\"\")\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(sesgadas, bins=30, alpha=0.7, label='Sesgado')\n",
    "    plt.title(f'Histograma de autocorrelación sesgada\\nnum_estimates = {num_estimates}')\n",
    "    plt.xlabel('Valor de autocorrelación')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(no_sesgadas, bins=30, alpha=0.7, label='No sesgado')\n",
    "    plt.title(f'Histograma de autocorrelación no sesgada\\nnum_estimates = {num_estimates}')\n",
    "    plt.xlabel('Valor de autocorrelación')\n",
    "    plt.ylabel('Frecuencia')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La autocorrelación en $k = 0$ es $\\displaystyle R_x(0) = E[x(n)^2]$, \n",
    "que equivale a $\\mathrm{Var}[x(n)] + \\bigl(E[x(n)]\\bigr)^2$. \n",
    "Si $x(n)$ tiene varianza 1 y media 1, \n",
    "entonces $R_x(0) = 2$.\n",
    "___ "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sistemas_Codif_Almacenamiento",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
