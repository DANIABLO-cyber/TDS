{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TUTORIAL SCA PYTHON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 SEÑALES DE AUDIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Lectura y almacenamiento de señales de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fs, s = wf.read('Datos/altura.wav')  # Leer archivo de audio\n",
    "\n",
    "mitad = int(len(s) / 2)  # Calcular el punto medio del audio\n",
    "s1 = s[:mitad]  # Primera mitad del audio\n",
    "s2 = s[mitad:]  # Segunda mitad del audio\n",
    "\n",
    "wf.write('Datos/audioInicial.wav', fs, s1)  # Guardar primera mitad\n",
    "wf.write('Datos/audioFinal.wav', fs, s2)  # Guardar segunda mitad\n",
    "\n",
    "s = s / np.max(np.abs(s))  # Normalizar la señal al rango (-1,1)\n",
    "wf.write('Datos/audioNormalizado.wav', fs, s)  # Guardar el audio normalizado\n",
    "\n",
    "# Crear un vector de tiempo\n",
    "t = np.arange(len(s)) / fs\n",
    "t1, t2 = t[:mitad], t[mitad:]\n",
    "\n",
    "#? Transformada de Fourier (solo parte positiva)\n",
    "N = len(s)\n",
    "frequencies = np.fft.fftfreq(N, d=1/fs)\n",
    "spectrum = np.abs(np.fft.fft(s))\n",
    "\n",
    "#? Representación gráfica compacta\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(t, s, color='blue')\n",
    "plt.xlabel(\"Tiempo (s)\")\n",
    "plt.ylabel(\"Amplitud\")\n",
    "plt.title(\"Señal de Audio Completa\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(t1, s1, color='green')\n",
    "plt.xlabel(\"Tiempo (s)\")\n",
    "plt.title(\"Primera Mitad del Audio\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(t2, s2, color='red')\n",
    "plt.xlabel(\"Tiempo (s)\")\n",
    "plt.title(\"Segunda Mitad del Audio\")\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(frequencies[:N//2], spectrum[:N//2], color='purple')  # Solo la mitad positiva\n",
    "plt.xlabel(\"Frecuencia (Hz)\")\n",
    "plt.ylabel(\"Magnitud\")\n",
    "plt.title(\"Espectro de la Señal\")\n",
    "plt.grid()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Representación y reproducción de señales de audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wf\n",
    "import matplotlib.pyplot as plt\n",
    "import sounddevice as sd\n",
    "\n",
    "# Leer el archivo de audio\n",
    "fs, s = wf.read('Datos/altura.wav')\n",
    "\n",
    "# Crear vector de tiempo\n",
    "t = np.arange(len(s)) / fs\n",
    "\n",
    "# Representar la señal en el dominio del tiempo\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.plot(t, s, color='blue')\n",
    "plt.xlabel(\"Tiempo (s)\")\n",
    "plt.ylabel(\"Amplitud\")\n",
    "plt.title(\"Señal de Audio en el Tiempo\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Reproducir el audio\n",
    "sd.play(s, fs)\n",
    "sd.wait()  # Espera hasta que termine la reproducción\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "duracion_segmento = 1  # Duración de cada segmento en segundos\n",
    "num_muestras = fs * duracion_segmento  # Número de muestras por segmento\n",
    "\n",
    "for i in range(0, len(s), num_muestras):\n",
    "    segmento = s[i:i + num_muestras]  # Extraer segmento\n",
    "    t_seg = np.arange(len(segmento)) / fs  # Vector de tiempo para el segmento\n",
    "\n",
    "#     # Representar el segmento\n",
    "#     plt.figure(figsize=(8, 2))\n",
    "#     plt.plot(t_seg, segmento, color='purple')\n",
    "#     plt.xlabel(\"Tiempo (s)\")\n",
    "#     plt.ylabel(\"Amplitud\")\n",
    "#     plt.title(f\"Segmento {i // num_muestras + 1}\")\n",
    "#     plt.grid()\n",
    "#     plt.show()\n",
    "\n",
    "#     # Guardar cada segmento en un archivo independiente\n",
    "#     wf.write(f'segmento_{i // num_muestras + 1}.wav', fs, segmento)\n",
    "\n",
    "for fs_nuevo in [fs, fs // 2, fs * 2]:  # Reproducir a fs normal, fs/2 y 2*fs\n",
    "    print(f\"Reproduciendo con frecuencia de muestreo: {fs_nuevo} Hz\")\n",
    "    sd.play(s, fs_nuevo)\n",
    "    sd.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Tasa de bits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io.wavfile as wf\n",
    "\n",
    "# Leer el archivo de audio\n",
    "fs, s = wf.read(\"Datos/altura.wav\")\n",
    "\n",
    "# Determinar el tipo de datos\n",
    "tipo_datos = s.dtype\n",
    "bits_por_muestra = s.itemsize * 8  # itemsize devuelve bytes, lo multiplicamos por 8 para bits\n",
    "\n",
    "# Calcular la duración del audio\n",
    "duracion = len(s) / fs\n",
    "\n",
    "# Determinar el rango dinámico de la señal\n",
    "rango_min = np.min(s)\n",
    "rango_max = np.max(s)\n",
    "\n",
    "# Mostrar resultados\n",
    "print(f\"Frecuencia de muestreo: {fs} Hz\")\n",
    "print(f\"Duración del audio: {duracion:.2f} segundos\")\n",
    "print(f\"Tipo de datos: {tipo_datos}\")\n",
    "print(f\"Bits por muestra: {bits_por_muestra} bits\")\n",
    "print(f\"Rango de valores: [{rango_min}, {rango_max}]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Manejo de señales de audio con pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from pydub import AudioSegment, playback\n",
    "import numpy as np\n",
    "\n",
    "# Cargar archivo de audio\n",
    "audio = AudioSegment.from_wav(\"altura.wav\")\n",
    "\n",
    "# Reproducir el audio\n",
    "playback.play(audio)\n",
    "\n",
    "# Extraer las muestras como array de numpy\n",
    "s = np.array(audio.get_array_of_samples())\n",
    "\n",
    "# Modificar la amplitud del audio (+5 dB)\n",
    "audio_amplificado = audio.apply_gain(5)\n",
    "\n",
    "# Obtener información del audio\n",
    "duracion = audio.duration_seconds\n",
    "frecuencia_muestreo = audio.frame_rate\n",
    "\n",
    "# Extraer un segmento de 1.5s a 2.0s\n",
    "segmento = audio[1500:2000]\n",
    "\n",
    "# Guardar el segmento como archivo WAV y MP3\n",
    "segmento.export(\"segmento.wav\", format=\"wav\")\n",
    "segmento.export(\"segmento.mp3\", format=\"mp3\")\n",
    "\n",
    "# Mostrar información relevante\n",
    "print(f\"Duración del audio: {duracion:.2f} segundos\")\n",
    "print(f\"Frecuencia de muestreo: {frecuencia_muestreo} Hz\")\n",
    "print(f\"Amplitud máxima del audio original: {max(s)}\")\n",
    "print(f\"Segmento guardado en 'segmento.wav' y 'segmento.mp3'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 IMÁGENES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Lectura y almacenamiento de imágenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "from skimage import io, color\n",
    "\n",
    "# Leer la imagen en RGB\n",
    "img = io.imread('Datos/lena.png')\n",
    "\n",
    "# Convertir la imagen a escala de grises\n",
    "img_gray = color.rgb2gray(img)\n",
    "\n",
    "# Guardar la imagen en formato JPEG\n",
    "io.imsave('lena_gray.jpg', img_gray)\n",
    "\n",
    "print(\"Imagen cargada y convertida a escala de grises correctamente.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sistemas_Codif_Almacenamiento",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
